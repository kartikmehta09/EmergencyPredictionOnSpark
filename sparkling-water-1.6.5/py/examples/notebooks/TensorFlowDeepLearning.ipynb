{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from pysparkling import H2OContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Demo-Specific configuration\n",
    "NODES=3 # Number of partitions to split data into (~simulate a number of nodes)\n",
    "DATASET_DIR=\"/users/nidhimehta/h2o-3/bigdata/laptop/mnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sparkling, TensorFlow!', 'Sparkling, TensorFlow!', 'Sparkling, TensorFlow!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Initialize TensorFlow session and test it\n",
    "def map_fun(i):\n",
    "  import tensorflow as tf\n",
    "  with tf.Graph().as_default() as g:\n",
    "    hello = tf.constant('Sparkling, TensorFlow!', name=\"hello_constant\")\n",
    "    with tf.Session() as sess:\n",
    "      return sess.run(hello)\n",
    "sc.parallelize(range(NODES), NODES).map(map_fun).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime: </td>\n",
       "<td>6 seconds 229 milliseconds </td></tr>\n",
       "<tr><td>H2O cluster version: </td>\n",
       "<td>3.8.2.2</td></tr>\n",
       "<tr><td>H2O cluster name: </td>\n",
       "<td>sparkling-water-nidhimehta_1121600612</td></tr>\n",
       "<tr><td>H2O cluster total nodes: </td>\n",
       "<td>3</td></tr>\n",
       "<tr><td>H2O cluster total free memory: </td>\n",
       "<td>2.88 GB</td></tr>\n",
       "<tr><td>H2O cluster total cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster allowed cores: </td>\n",
       "<td>24</td></tr>\n",
       "<tr><td>H2O cluster healthy: </td>\n",
       "<td>True</td></tr>\n",
       "<tr><td>H2O Connection ip: </td>\n",
       "<td>192.168.1.100</td></tr>\n",
       "<tr><td>H2O Connection port: </td>\n",
       "<td>54329</td></tr>\n",
       "<tr><td>H2O Connection proxy: </td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>Python Version: </td>\n",
       "<td>2.7.6</td></tr></table></div>"
      ],
      "text/plain": [
       "------------------------------  -------------------------------------\n",
       "H2O cluster uptime:             6 seconds 229 milliseconds\n",
       "H2O cluster version:            3.8.2.2\n",
       "H2O cluster name:               sparkling-water-nidhimehta_1121600612\n",
       "H2O cluster total nodes:        3\n",
       "H2O cluster total free memory:  2.88 GB\n",
       "H2O cluster total cores:        24\n",
       "H2O cluster allowed cores:      24\n",
       "H2O cluster healthy:            True\n",
       "H2O Connection ip:              192.168.1.100\n",
       "H2O Connection port:            54329\n",
       "H2O Connection proxy:\n",
       "Python Version:                 2.7.6\n",
       "------------------------------  -------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n"
     ]
    }
   ],
   "source": [
    "## Read MNIST data into H2O\n",
    "import h2o\n",
    "h2o.__version__\n",
    "hc = H2OContext(sc).start()\n",
    "train_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"train.csv.gz\"))\n",
    "test_frame = h2o.import_file(\"{}/{}\".format(DATASET_DIR, \"test.csv.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Turn H2O DataFrame into a Spark DataFrame\n",
    "train_df = hc.as_spark_frame(train_frame).repartition(NODES)\n",
    "test_df = hc.as_spark_frame(test_frame).repartition(NODES)\n",
    "#train_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Configure a TensorFlow Deep Learning model\n",
    "\n",
    "# - it loads local training data into numpy array (from Spark -> Python)\n",
    "# - train TF Deep Learning model with 1 hidden layer (50 neurons)\n",
    "# - output accuracy on training data\n",
    "def create_nn(data_train, data_test, iterations, batch_size):\n",
    "    import tensorflow as tf\n",
    "    # Symbolic computation\n",
    "    x = tf.placeholder(tf.float32, [None, 784])\n",
    "    W1 = tf.Variable(tf.random_normal([784, 50],stddev=0.1))\n",
    "    W2 = tf.Variable(tf.random_normal([50, 10],stddev=0.1))\n",
    "    b1 = tf.Variable(tf.random_normal([50],stddev=0.1))\n",
    "    b2 = tf.Variable(tf.random_normal([10],stddev=0.1))\n",
    "    hidden = tf.nn.relu(tf.matmul(x, W1) + b1)\n",
    "    y = tf.nn.softmax(tf.matmul(hidden, W2) + b2)\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "    cross_entropy = -tf.reduce_sum(y_*tf.log(y))                    \n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)\n",
    "    \n",
    "    # Initialize TF\n",
    "    init = tf.initialize_all_variables()\n",
    "    sess = tf.Session()\n",
    "    sess.run(init)\n",
    "    print(\"Training TensorFlow Deep Learning model\")\n",
    "    for i in range(iterations):\n",
    "      #print(\"TensorFlow iter: \", i, \" session: \", sess)\n",
    "      batch_xs, batch_ys = data_train.next_batch(batch_size)\n",
    "      sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        \n",
    "    model = [(sess.run(W1),sess.run(W2),sess.run(b1),sess.run(b2))]\n",
    "\n",
    "    # Model evaluation\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n",
    "    batch_xs, batch_ys = data_test.next_batch(1000)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"Training Accuracy:\", sess.run(accuracy, feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    #print(sess.run(tf.argmax(y,1), feed_dict={x: batch_xs, y_: batch_ys}))\n",
    "    \n",
    "    sess.close()\n",
    "    return iter(model)\n",
    "    \n",
    "    # Export the model\n",
    "    #from tensorflow_serving.session_bundle import exporter\n",
    "    #export_path = \"/tmp/xxx/\"\n",
    "    #saver = tf.train.Saver(sharded=True)\n",
    "    #model_exporter = exporter.Exporter(saver)\n",
    "    #signature = exporter.classification_signature(input_tensor=x, scores_tensor=y)\n",
    "    #model_exporter.init(sess.graph.as_graph_def(), default_graph_signature=signature)\n",
    "    #model_exporter.export(export_path, tf.constant(FLAGS.export_version), sess)\n",
    "    \n",
    "## Internal Helpers\n",
    "\n",
    "# Sampling with replacement to provide a batch size\n",
    "# Load everything into numpy datastructure\n",
    "import numpy as np\n",
    "\n",
    "def expand1hot(response, levels):\n",
    "    nrows = response.shape[0]\n",
    "    result = np.zeros((nrows, levels), dtype=np.float32)\n",
    "    result[np.arange(nrows), response.astype(np.int8)] = 1.0\n",
    "    return result\n",
    "\n",
    "class RowData:\n",
    "    def __init__(self, it):\n",
    "        self._part_array = np.array([ [a for a in x] for x in it], dtype=np.float32)\n",
    "        # Definition of input features\n",
    "        self._x = range(784)\n",
    "        # Index of response\n",
    "        self._y = 784\n",
    "\n",
    "    def next_batch(self, n):\n",
    "        # Sample from local data without replacement\n",
    "        dim = self._part_array.shape[0] # number of rows\n",
    "        sample = np.random.choice(dim, n, replace=False)\n",
    "        data = self._part_array[sample, :]\n",
    "        # Data comming from H2O, pixel values are 0..255\n",
    "        # FIXME: this should be done via RDD or H2O API directly !\n",
    "        train = data[:, self._x]/255 \n",
    "        response = expand1hot(data[:, self._y], 10)\n",
    "        return (train, response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Run TensorFlow on each node\n",
    "\n",
    "# Number of iterations\n",
    "ITERATIONS = 100\n",
    "# Batch size\n",
    "BATCH_SIZE = 100\n",
    "# Use Mnist dataset provided by TensorFlow - for debugging only\n",
    "USE_TF_MNIST=False\n",
    "\n",
    "def train_nn(iterations, batch_size, use_tf_mnist=False):\n",
    "    def perPartition(it):\n",
    "        if not use_tf_mnist:\n",
    "            train_data = RowData(it)\n",
    "            test_data = train_data\n",
    "        else:\n",
    "            from tensorflow.examples.tutorials.mnist import input_data\n",
    "            mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "            train_data = mnist.train\n",
    "            test_data = mnist.train\n",
    "            \n",
    "        return create_nn(train_data, test_data, iterations, batch_size)\n",
    "        \n",
    "    return perPartition\n",
    "\n",
    "modelsPerNode = train_df.mapPartitions(train_nn(ITERATIONS, BATCH_SIZE, USE_TF_MNIST)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.07291194 -0.02839035 -0.07471841 -0.04402993 -0.02235463 -0.02620575\n",
      "  0.1163722  -0.10408342  0.03329315  0.02185328 -0.01488095 -0.04401837\n",
      "  0.01081673 -0.08093681  0.00062102  0.18718861  0.10789666 -0.03121319\n",
      "  0.01584251  0.02999378  0.00920764  0.01968472 -0.22378016 -0.00778377\n",
      " -0.03973616  0.03197502 -0.0680975   0.04697173  0.03519468 -0.00212386\n",
      "  0.02742671 -0.14775626 -0.02035625  0.08105865  0.00861828 -0.00487186\n",
      " -0.08079082  0.02739912  0.00801532 -0.10542602  0.12667958 -0.03169039\n",
      "  0.03707669 -0.14269291 -0.08280306 -0.00424655 -0.03680487 -0.03225352\n",
      "  0.09846754 -0.09231455]\n",
      "[-0.31967929 -0.20698647 -0.16512461  0.15594698  0.11046103  0.28740093\n",
      " -0.05201261 -0.25301719  0.40938249  0.17546685]\n"
     ]
    }
   ],
   "source": [
    "# Average the weights and biases across all node-local models\n",
    "W1 = modelsPerNode[0][0]\n",
    "W2 = modelsPerNode[0][1]\n",
    "b1 = modelsPerNode[0][2]\n",
    "b2 = modelsPerNode[0][3]\n",
    "\n",
    "AVERAGE = True\n",
    "\n",
    "if (AVERAGE):\n",
    "  for i in range(1,NODES):\n",
    "    W1 = W1 + modelsPerNode[i][0]\n",
    "    W2 = W2 + modelsPerNode[i][1]\n",
    "    b1 = b1 + modelsPerNode[i][2]\n",
    "    b2 = b2 + modelsPerNode[i][3]\n",
    "\n",
    "W1 = W1/NODES\n",
    "W2 = W2/NODES\n",
    "b1 = b1/NODES\n",
    "b2 = b2/NODES\n",
    "\n",
    "#print(W1)\n",
    "#print(W2)\n",
    "print(b1)\n",
    "print(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W1 = np.transpose(W1)\n",
    "W2 = np.transpose(W2)\n",
    "b1 = np.matrix(b1)\n",
    "b1 = np.transpose(b1)\n",
    "b2 = np.matrix(b2)\n",
    "b2 = np.transpose(b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "Parse Progress: [##################################################] 100%\n",
      "\n",
      "deeplearning Model Build Progress: [                                                  ] 00%\n"
     ]
    }
   ],
   "source": [
    "#Initialize an H2O Model with those weights/biases\n",
    "#from pysparkling import *\n",
    "from h2o.estimators.deeplearning import H2ODeepLearningEstimator\n",
    "\n",
    "## Create an H2O Deep Learning model from the TensorFlow model\n",
    "dlmodel = H2ODeepLearningEstimator(\n",
    "    hidden=[50],             ## same Network layout as TF - one hidden layer\n",
    "    epochs=0,                ## no training done in H2O - just copy over the model from TF\n",
    "    ignore_const_cols=False  ## keep all input features (unless we also drop const cols in TF)\n",
    "    \n",
    "    ### Initialize the H2O model with the TensorFlow model state\n",
    "    ### Requires H2O 3.8.2.1 or later\n",
    "    ,initial_weights=[h2o.H2OFrame(W1.tolist()),h2o.H2OFrame(W2.tolist())]\n",
    "    ,initial_biases=[h2o.H2OFrame(b1.tolist()),h2o.H2OFrame(b2.tolist())]\n",
    ")\n",
    "train_frame[784] = train_frame[784].asfactor()\n",
    "dlmodel.train(x=list(range(784)),y=784,training_frame=train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ModelMetricsMultinomial: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.234191312262\n",
      "R^2: 0.971945558294\n",
      "LogLoss: 0.88625787961\n",
      "\n",
      "Confusion Matrix: vertical: actual; across: predicted\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>0</b></td>\n",
       "<td><b>1</b></td>\n",
       "<td><b>2</b></td>\n",
       "<td><b>3</b></td>\n",
       "<td><b>4</b></td>\n",
       "<td><b>5</b></td>\n",
       "<td><b>6</b></td>\n",
       "<td><b>7</b></td>\n",
       "<td><b>8</b></td>\n",
       "<td><b>9</b></td>\n",
       "<td><b>Error</b></td>\n",
       "<td><b>Rate</b></td></tr>\n",
       "<tr><td>4886.0</td>\n",
       "<td>3.0</td>\n",
       "<td>137.0</td>\n",
       "<td>72.0</td>\n",
       "<td>32.0</td>\n",
       "<td>442.0</td>\n",
       "<td>163.0</td>\n",
       "<td>37.0</td>\n",
       "<td>3.0</td>\n",
       "<td>148.0</td>\n",
       "<td>0.1750802</td>\n",
       "<td>1,037 / 5,923</td></tr>\n",
       "<tr><td>2.0</td>\n",
       "<td>2233.0</td>\n",
       "<td>1115.0</td>\n",
       "<td>805.0</td>\n",
       "<td>5.0</td>\n",
       "<td>1576.0</td>\n",
       "<td>2.0</td>\n",
       "<td>992.0</td>\n",
       "<td>1.0</td>\n",
       "<td>11.0</td>\n",
       "<td>0.6687926</td>\n",
       "<td>4,509 / 6,742</td></tr>\n",
       "<tr><td>18.0</td>\n",
       "<td>9.0</td>\n",
       "<td>5289.0</td>\n",
       "<td>130.0</td>\n",
       "<td>126.0</td>\n",
       "<td>100.0</td>\n",
       "<td>96.0</td>\n",
       "<td>124.0</td>\n",
       "<td>8.0</td>\n",
       "<td>58.0</td>\n",
       "<td>0.1122860</td>\n",
       "<td>669 / 5,958</td></tr>\n",
       "<tr><td>14.0</td>\n",
       "<td>16.0</td>\n",
       "<td>217.0</td>\n",
       "<td>4868.0</td>\n",
       "<td>16.0</td>\n",
       "<td>774.0</td>\n",
       "<td>20.0</td>\n",
       "<td>98.0</td>\n",
       "<td>3.0</td>\n",
       "<td>105.0</td>\n",
       "<td>0.2060023</td>\n",
       "<td>1,263 / 6,131</td></tr>\n",
       "<tr><td>8.0</td>\n",
       "<td>2.0</td>\n",
       "<td>38.0</td>\n",
       "<td>10.0</td>\n",
       "<td>4909.0</td>\n",
       "<td>119.0</td>\n",
       "<td>42.0</td>\n",
       "<td>19.0</td>\n",
       "<td>0.0</td>\n",
       "<td>695.0</td>\n",
       "<td>0.1597056</td>\n",
       "<td>933 / 5,842</td></tr>\n",
       "<tr><td>15.0</td>\n",
       "<td>4.0</td>\n",
       "<td>83.0</td>\n",
       "<td>252.0</td>\n",
       "<td>74.0</td>\n",
       "<td>4785.0</td>\n",
       "<td>55.0</td>\n",
       "<td>25.0</td>\n",
       "<td>2.0</td>\n",
       "<td>126.0</td>\n",
       "<td>0.1173215</td>\n",
       "<td>636 / 5,421</td></tr>\n",
       "<tr><td>30.0</td>\n",
       "<td>9.0</td>\n",
       "<td>128.0</td>\n",
       "<td>4.0</td>\n",
       "<td>379.0</td>\n",
       "<td>326.0</td>\n",
       "<td>4983.0</td>\n",
       "<td>35.0</td>\n",
       "<td>2.0</td>\n",
       "<td>22.0</td>\n",
       "<td>0.1579926</td>\n",
       "<td>935 / 5,918</td></tr>\n",
       "<tr><td>1.0</td>\n",
       "<td>2.0</td>\n",
       "<td>144.0</td>\n",
       "<td>99.0</td>\n",
       "<td>80.0</td>\n",
       "<td>74.0</td>\n",
       "<td>2.0</td>\n",
       "<td>5055.0</td>\n",
       "<td>0.0</td>\n",
       "<td>808.0</td>\n",
       "<td>0.1931365</td>\n",
       "<td>1,210 / 6,265</td></tr>\n",
       "<tr><td>10.0</td>\n",
       "<td>125.0</td>\n",
       "<td>387.0</td>\n",
       "<td>383.0</td>\n",
       "<td>203.0</td>\n",
       "<td>1898.0</td>\n",
       "<td>151.0</td>\n",
       "<td>66.0</td>\n",
       "<td>1609.0</td>\n",
       "<td>1019.0</td>\n",
       "<td>0.7250043</td>\n",
       "<td>4,242 / 5,851</td></tr>\n",
       "<tr><td>13.0</td>\n",
       "<td>0.0</td>\n",
       "<td>59.0</td>\n",
       "<td>97.0</td>\n",
       "<td>172.0</td>\n",
       "<td>153.0</td>\n",
       "<td>6.0</td>\n",
       "<td>172.0</td>\n",
       "<td>1.0</td>\n",
       "<td>5276.0</td>\n",
       "<td>0.1131283</td>\n",
       "<td>673 / 5,949</td></tr>\n",
       "<tr><td>4997.0</td>\n",
       "<td>2403.0</td>\n",
       "<td>7597.0</td>\n",
       "<td>6720.0</td>\n",
       "<td>5996.0</td>\n",
       "<td>10247.0</td>\n",
       "<td>5520.0</td>\n",
       "<td>6623.0</td>\n",
       "<td>1629.0</td>\n",
       "<td>8268.0</td>\n",
       "<td>0.26845</td>\n",
       "<td>16,107 / 60,000</td></tr></table></div>"
      ],
      "text/plain": [
       "0     1     2     3     4     5      6     7     8     9     Error     Rate\n",
       "----  ----  ----  ----  ----  -----  ----  ----  ----  ----  --------  ---------------\n",
       "4886  3     137   72    32    442    163   37    3     148   0.17508   1,037 / 5,923\n",
       "2     2233  1115  805   5     1576   2     992   1     11    0.668793  4,509 / 6,742\n",
       "18    9     5289  130   126   100    96    124   8     58    0.112286  669 / 5,958\n",
       "14    16    217   4868  16    774    20    98    3     105   0.206002  1,263 / 6,131\n",
       "8     2     38    10    4909  119    42    19    0     695   0.159706  933 / 5,842\n",
       "15    4     83    252   74    4785   55    25    2     126   0.117322  636 / 5,421\n",
       "30    9     128   4     379   326    4983  35    2     22    0.157993  935 / 5,918\n",
       "1     2     144   99    80    74     2     5055  0     808   0.193136  1,210 / 6,265\n",
       "10    125   387   383   203   1898   151   66    1609  1019  0.725004  4,242 / 5,851\n",
       "13    0     59    97    172   153    6     172   1     5276  0.113128  673 / 5,949\n",
       "4997  2403  7597  6720  5996  10247  5520  6623  1629  8268  0.26845   16,107 / 60,000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-10 Hit Ratios: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td><b>k</b></td>\n",
       "<td><b>hit_ratio</b></td></tr>\n",
       "<tr><td>1</td>\n",
       "<td>0.73155</td></tr>\n",
       "<tr><td>2</td>\n",
       "<td>0.8636333</td></tr>\n",
       "<tr><td>3</td>\n",
       "<td>0.9170666</td></tr>\n",
       "<tr><td>4</td>\n",
       "<td>0.9535166</td></tr>\n",
       "<tr><td>5</td>\n",
       "<td>0.9754833</td></tr>\n",
       "<tr><td>6</td>\n",
       "<td>0.9907500</td></tr>\n",
       "<tr><td>7</td>\n",
       "<td>0.9953833</td></tr>\n",
       "<tr><td>8</td>\n",
       "<td>0.9980333</td></tr>\n",
       "<tr><td>9</td>\n",
       "<td>0.9993666</td></tr>\n",
       "<tr><td>10</td>\n",
       "<td>1.0</td></tr></table></div>"
      ],
      "text/plain": [
       "k    hit_ratio\n",
       "---  -----------\n",
       "1    0.73155\n",
       "2    0.863633\n",
       "3    0.917067\n",
       "4    0.953517\n",
       "5    0.975483\n",
       "6    0.99075\n",
       "7    0.995383\n",
       "8    0.998033\n",
       "9    0.999367\n",
       "10   1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check the model performance - Will only be good if we actually copied the TF model into the H2O model above\n",
    "dlmodel.model_performance(train_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Now we have a POJO for the TensorFlow model!\n",
    "dlmodel.download_pojo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
